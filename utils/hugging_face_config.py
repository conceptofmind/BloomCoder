from typing import Optional, ClassVar
from dataclasses import dataclass, field

@dataclass
class CFG:

    """
    Configuration for data loader.
    """

    train_dataset_name: Optional[str] = field(
        default="codeparrot/codeparrot-train-v2-near-dedup", 
        metadata={"help": "Path to Hugging Face training dataset."}
    )

    eval_dataset_name: Optional[str] = field(
        default="codeparrot/codeparrot-valid-v2-near-dedup", 
        metadata={"help": "Path to Hugging Face validation dataset."}
    )

    choose_train_split: Optional[str] = field(
        default="train", 
        metadata={"help": "Choose Hugging Face training dataset split."}
    )

    choose_eval_split: Optional[str] = field(
        default="train", 
        metadata={"help": "Choose Hugging Face validation dataset split."}
    )

    remove_train_columns: ClassVar[list[str]] = field(
        default = [
            'copies', 
            'path', 
            'repo_name', 
            'size', 
            'license', 
            'hash', 
            'line_mean', 
            'line_max', 
            'alpha_frac', 
            'autogenerated',
            'ratio',
            'config_test',
            'has_no_keywords',
            'few_assignments',
        ], 
        metadata={"help": "Train dataset columns to remove."}
    )

    remove_eval_columns: ClassVar[list[str]] = field(
        default = [
            'copies', 
            'path', 
            'repo_name', 
            'size', 
            'license', 
            'hash', 
            'line_mean', 
            'line_max', 
            'alpha_frac', 
            'autogenerated',
            'ratio',
            'config_test',
            'has_no_keywords',
            'few_assignments',
        ], 
        metadata={"help": "Validation dataset columns to remove."}
    )

    seed: Optional[int] = field(
        default=42, 
        metadata={"help": "Random seed used for reproducibility."}
    )

    tokenizer_name: Optional[str] = field(
        default="bigscience/bloom-1b3",
        metadata={"help": "Tokenizer name."}
    )

    tokenizer_seq_length: Optional[int] = field(
        default=512, 
        metadata={"help": "Sequence lengths used for tokenizing examples."}
    )

    select_input_string: Optional[str] = field(
        default="content", 
        metadata={"help": "Select the key to used as the input string column."}
    )
    
    batch_size: Optional[int] = field(
        default=16, 
        metadata={"help": "Batch size for training and validation."}
    )

    save_to_path: Optional[str] = field(
        default="''", 
        metadata={"help": "Save the dataset to local disk."}
    )